questionName,correctAnswer,incorrectAnswerA,incorrectAnswerB,incorrectAnswerC,difficulty,topicCode,feedback
What is the main purpose of the CPU?,To execute instructions by performing fetch–decode–execute,To permanently store files,To display graphics on the screen,To provide network access,Easy,1.1,"The CPU runs the fetch–decode–execute cycle to process instructions. Storage, graphics, and networking are handled by other components."
Which stage comes first in the fetch–decode–execute cycle?,Fetch,Decode,Execute,Store,Easy,1.1,"The cycle begins by fetching the next instruction from memory, then decoding it, then executing it; there is no ‘store’ stage in OCR J277’s description."
Which CPU component performs arithmetic and logic operations?,ALU,CU,Cache,Register,Easy,1.1,The ALU carries out arithmetic and logic. The CU coordinates control signals. Cache stores frequently used data. Registers hold tiny amounts of fast data/addresses.
Which CPU component coordinates the activities of the CPU?,Control Unit (CU),ALU,GPU,Power supply,Easy,1.1,The CU issues control signals to manage the fetch–decode–execute cycle. The ALU calculates; the GPU and PSU are not CPU components.
What is the main benefit of CPU cache?,It provides faster access to frequently used data,It increases permanent storage capacity,It cools the processor,It displays error messages,Easy,1.1,"Cache is small, very fast memory close to the CPU to reduce main-memory access time. It is not storage, cooling, or a display feature."
What is a register?,"A very small, very fast storage location inside the CPU",A removable storage device,A background process,A type of software,Easy,1.1,"Registers hold data or addresses during processing. They are hardware locations inside the CPU, not external devices or software."
"In the Von Neumann model, which register holds the address of the next instruction to fetch?",Program Counter (PC),Accumulator,MDR,ALU,Easy,1.1,The PC stores the memory address of the next instruction. The Accumulator stores results; the MDR stores data; the ALU is not a register.
Which register holds the address of the data or instruction to access in memory?,MAR,MDR,PC,Accumulator,Easy,1.1,"The MAR holds addresses. The MDR holds the data itself, the PC holds the next instruction address, and the Accumulator holds results."
Which register holds the actual data just fetched from or to be written to memory?,MDR,MAR,PC,CU,Easy,1.1,The MDR stores data being transferred to/from memory. MAR stores addresses; PC holds the next instruction’s address; CU is not a register.
Which register commonly stores the result of ALU operations?,Accumulator,PC,MAR,MDR,Easy,1.1,The Accumulator holds intermediate results. PC is for next instruction address; MAR and MDR handle addresses and data for memory access.
What does the CPU do during the ‘fetch’ stage?,Gets the next instruction from memory,Sends results to output devices,Checks for viruses,Writes to secondary storage,Easy,1.1,"‘Fetch’ retrieves the instruction from memory via MAR/MDR. Output, security scanning, and secondary storage are unrelated to this stage."
"During the ‘decode’ stage, what happens?",The instruction is interpreted to determine required actions,The next instruction is fetched,Data is saved to disk,The screen is refreshed,Easy,1.1,Decode interprets the opcode and operands to prepare the control signals. Fetch and execute are other stages; disk and display are unrelated.
"During the ‘execute’ stage, what happens?",The CPU carries out the instruction,The instruction is loaded from disk,The program counter resets to zero,The CPU clears the cache,Easy,1.1,"Execute performs the action (e.g., ALU operation, memory read/write). Loading from disk and clearing cache are not parts of the standard stage."
Which architecture stores programs and data in the same memory?,Von Neumann,Harvard,RISC-V,CISC,Easy,1.1,"Von Neumann uses a single memory for programs and data. Harvard uses separate memories; RISC-V and CISC are ISA styles, not memory models here."
What does ‘clock speed’ measure?,The number of cycles per second the CPU can perform,Amount of data the CPU can store,The size of the monitor,Network bandwidth,Easy,1.1,"Clock speed (Hz) is the cycles per second. Storage capacity, screen size, and network speed are unrelated."
Increasing clock speed generally…,Allows more instructions to be processed per second,Adds more RAM capacity,Improves screen resolution,Guarantees longer battery life,Easy,1.1,"Higher clock means more cycles per second, potentially more instructions executed. It does not add RAM, change display, or assure battery life."
What does ‘number of cores’ refer to?,How many independent processing units are on the CPU chip,How many programs are installed,How many threads exist in software,How many sockets are on the motherboard,Easy,1.1,"Cores are separate processing units in the CPU. Software threads, programs, and motherboard sockets are different concepts."
What does a larger cache size usually do?,Reduces the time waiting for data from main memory,Increases hard-drive speed,Improves Wi‑Fi,Increases screen brightness,Easy,1.1,"More cache can hold more frequently accessed data close to the CPU, reducing main memory access delays. It doesn’t affect storage, Wi‑Fi, or display."
Which of these is an embedded system?,A washing machine controller,A desktop PC,A server rack,A laptop used for gaming,Easy,1.1,"A washing machine controller is a dedicated computer within a larger device. PCs, servers, and laptops are general-purpose systems."
A key characteristic of embedded systems is that they are…,Dedicated to a specific task,Designed for many unrelated tasks,Always upgradeable by the user,Always require a monitor and keyboard,Easy,1.1,Embedded systems run a narrow set of functions for a device. They are not general-purpose and often lack user-upgradeable parts or full I/O.
Which of the following best describes the Control Unit’s role?,It controls the flow of data and issues control signals,It stores the operating system,It connects the CPU to the internet,It cools the CPU,Easy,1.1,"The CU orchestrates the FDE cycle with control signals. Storage, networking, and cooling are not its functions."
What does the Program Counter store?,The address of the next instruction,The result of the last calculation,The contents of cache,The address of the last data item only,Easy,1.1,The PC holds the next instruction address. Results are in the Accumulator; cache is separate; the PC is not limited to data addresses.
What does the MAR store?,A memory address,A data value,A list of programs,A picture,Easy,1.1,"MAR = Memory Address Register; it stores addresses, not data values, program lists, or images."
What does the MDR store?,Data read from or to be written to memory,The address of the next instruction,Control signals,Screen pixels,Easy,1.1,MDR = Memory Data Register; it stores data in transfer. The PC stores next address; CU handles control; pixels are irrelevant.
Which component would add two numbers?,ALU,CU,Cache,PC,Easy,1.1,The ALU performs arithmetic like addition. CU coordinates; cache stores data; PC holds the next address.
Which statement about cache is true?,Cache is faster but smaller than RAM,Cache is slower and larger than RAM,Cache is the same as secondary storage,Cache is only used by the GPU,Easy,1.1,"Cache is small and very fast, sitting close to the CPU. It is not secondary storage and not GPU-only."
What does the term ‘address’ refer to in memory operations?,A location identifier in memory,An email account,A password,A file extension,Easy,1.1,"An address identifies where data/instructions reside in memory. It is not an email, a password, or a file type."
Which is an example of an embedded system?,A digital thermostat,A cloud data center,A gaming PC,A developer workstation,Easy,1.1,A thermostat’s microcontroller runs a dedicated control task. The others are general-purpose systems.
Which register most closely interacts with main memory addresses?,MAR,Accumulator,ALU,Cache,Easy,1.1,The MAR holds memory addresses for access. Accumulator/ALU handle computation; cache is memory but doesn’t hold the specific target address.
"During fetch, which register’s value is copied into the MAR? (conceptually)",Program Counter (PC),Accumulator,ALU,Cache index,Easy,1.1,"Conceptually, the PC’s address is used to set MAR for the memory read. Accumulator and ALU are unrelated; cache index isn’t a register."
What is typically stored in the Accumulator?,Results of recent calculations,Next instruction address,Network packets,File names,Easy,1.1,The Accumulator holds intermediate results. The PC stores the next address; network packets and filenames are not register contents.
Which factor is LEAST likely to directly improve CPU performance?,Increasing screen size,Increasing clock speed,Increasing cache size,Adding more cores,Easy,1.1,"Performance factors include clock, cache, and cores. Screen size does not affect CPU performance."
Which best describes the fetch–decode–execute cycle?,A repeated process to run program instructions,A one‑time boot‑up routine,A network handshake,A graphics rendering pipeline,Easy,1.1,The CPU continuously repeats FDE to run programs. The other options are unrelated processes.
What is the effect of more cores for programs that are well parallelised?,More tasks can be processed simultaneously,Programs always run slower,Cache is disabled,RAM is doubled,Easy,1.1,"More cores allow parallel execution, improving speed for parallel workloads. They don’t disable cache or change RAM size."
A smartwatch’s processor is best described as…,An embedded system,A mainframe,A supercomputer,A general-purpose desktop,Easy,1.1,"The watch uses a dedicated processor inside a device: an embedded system, not a mainframe/supercomputer/desktop."
"In Von Neumann architecture, programs and data…",Share the same memory and buses,Use separate memories by design,Are executed only from cache,Are stored only on disk,Easy,1.1,Von Neumann uses a single memory for both. Separate memories describe Harvard. Cache/disk statements are incorrect.
Which register would change after each instruction fetch?,Program Counter (PC),Accumulator,ALU,Cache tag,Easy,1.1,The PC increments (or is updated on a jump) after fetch. Accumulator/ALU and cache tag are not the correct answers here.
What does the CU NOT do?,Store long‑term files,Issue control signals,Coordinate components,Manage the FDE cycle,Easy,1.1,The CU coordinates and issues control signals. File storage is not its role.
Which is a typical characteristic of embedded systems?,Low power and limited memory,High-end graphics cards,Multiple user accounts by default,Large interchangeable hard drives,Easy,1.1,Embedded systems are often resource‑constrained. The other options describe general-purpose computers.
Which single change is most likely to speed up memory-heavy tasks?,Increasing cache size,Decreasing clock speed,Removing cores,Using a smaller battery,Easy,1.1,A larger cache can reduce memory access delays. Lower clock or fewer cores reduce performance; battery size is unrelated.
Which register holds data moving between CPU and memory?,MDR,MAR,PC,IR (Instruction Register),Easy,1.1,MDR stores data in transit to/from memory. MAR holds addresses; PC holds next instruction address; IR is not in this spec list.
"Which component is primarily responsible for logic comparisons (e.g., equal, greater‑than)?",ALU,CU,Cache,PC,Easy,1.1,The ALU performs arithmetic and logical comparisons. CU controls; cache stores; PC tracks addresses.
"During fetch, which pair of registers primarily handle the address and the data?",MAR and MDR,PC and Accumulator,CU and ALU,Cache and GPU,Medium,1.1,Fetch uses MAR for the address and MDR for the data. The PC points to the next instruction; CU/ALU coordinate/compute; GPU is unrelated.
What happens to the Program Counter after a normal (non‑branch) instruction is fetched?,It is incremented to the next instruction address,It is cleared to zero,It is copied into the Accumulator,It is written to disk,Medium,1.1,"Typically PC increments to point at the next instruction. It isn’t cleared, stored in the Accumulator, or written to disk during FDE."
Why does a larger cache often improve performance?,It increases the hit rate for recently/frequently used data,It increases RAM capacity significantly,It runs at a lower voltage,It replaces the need for registers,Medium,1.1,"More cache holds more useful data close to the CPU, leading to more hits and fewer slow RAM accesses. It doesn’t replace RAM or registers."
How can multiple cores speed up some programs?,By executing different tasks or threads in parallel,By increasing disk capacity,By increasing screen refresh rate,By replacing the CU with another ALU,Medium,1.1,"Cores allow parallel execution when software supports it. Disk, display, and swapping CU/ALU are irrelevant."
"If two CPUs are identical except one has double the clock speed, which is generally true?",The higher‑clock CPU can execute more cycles per second,It always uses less power,It always has more RAM,It has fewer cores,Medium,1.1,"Higher clock means more cycles per second, which can increase performance. Power, RAM, and cores are not implied."
Which component issues control signals to regulate data flow and operations?,Control Unit,ALU,Accumulator,MDR,Medium,1.1,The CU controls the operation of the CPU. The ALU computes; Accumulator stores results; MDR stores data in transit.
Which register most likely stores an operand used by the ALU during execute?,Accumulator,PC,MAR,MDR only,Medium,1.1,The Accumulator commonly holds operands/results for the ALU. The PC holds addresses of instructions; MAR holds addresses; MDR stores data in transit.
"In Von Neumann architecture, what is a potential drawback of sharing buses for instructions and data?",The CPU may have to wait if both contend for the same bus,Programs cannot be stored in memory,ALU cannot access the Accumulator,Cache cannot be used,Medium,1.1,"A shared bus can cause contention, sometimes called the von Neumann bottleneck. The other statements are false."
Which change most benefits a workload that frequently reuses the same small data set?,Larger cache,More cores with the same cache,A bigger hard drive,Lower‑resolution monitor,Medium,1.1,A larger cache raises the chance that reused data is served quickly. More cores won’t help reuse if data is memory‑bound; storage/display are irrelevant.
A device that senses temperature and toggles a relay automatically is best categorised as…,An embedded system,A timesharing mainframe,A gaming rig,A thin client,Medium,1.1,It is a dedicated controller inside a device: embedded. The other options are general-purpose or enterprise systems.
Which correctly pairs register with what it stores?,"MAR – address, MDR – data","MAR – data, MDR – address","PC – data, Accumulator – address","Accumulator – address, PC – data",Medium,1.1,"MAR holds memory addresses; MDR holds the data. PC stores next instruction address; Accumulator stores results, not addresses."
"If an instruction requires data from memory, which register will first be set with the target address?",MAR,MDR,Accumulator,ALU,Medium,1.1,The MAR is loaded with the address to access. MDR carries the data; Accumulator/ALU are used for computation.
When might increasing the number of cores NOT improve performance?,When the program cannot be parallelised effectively,When the cache is large,When RAM is fast,When the screen is small,Medium,1.1,"If software can’t use multiple threads/tasks, extra cores won’t help. Cache/RAM/screen size don’t directly prevent scaling."
"In the decode stage, which component mainly interprets the instruction?",Control Unit,ALU,Cache,Accumulator,Medium,1.1,The CU decodes the instruction and orchestrates signals. ALU computes; cache stores; Accumulator holds values.
Which is a typical constraint of embedded systems?,Limited memory and processing power to save cost and energy,Always user‑replaceable CPUs,Multiple high‑end GPUs,Large amounts of upgradeable RAM,Medium,1.1,Embedded devices are built for specific tasks with constrained resources. User upgrades and high‑end GPUs are uncommon.
Which best explains why cache is faster than RAM?,It is smaller and built with faster memory close to the CPU,It is stored on disk platters,It uses wireless transmission,It is managed by the GPU,Medium,1.1,"Cache uses fast memory close to the CPU. Disks, wireless, and GPU management are unrelated."
Which describes a common feature of embedded systems’ software?,Firmware stored in ROM/flash tailored to the device,General‑purpose OS with many desktop apps,Cloud‑only execution,Daily manual installation by the user,Medium,1.1,"Embedded devices often use firmware closely matched to hardware. Desktop OSes, cloud‑only, and daily installs are not typical."
What is the immediate effect of a cache miss?,The CPU must fetch data from slower main memory,The PC resets to zero,The ALU shuts down,The number of cores decreases,Medium,1.1,"On a miss, the required data must be loaded from RAM, which is slower. The PC, ALU, and core count are unaffected."
Why might a CPU with lower clock speed still outperform another with higher clock?,"It may have more cores and larger cache, benefiting the workload",It uses a darker case color,It has more USB ports,It has a bigger monitor,Medium,1.1,"Performance depends on a combination of cores, cache, and workload characteristics—not case color, ports, or display."
Which statement about the Accumulator is correct?,It temporarily stores results and operands for the ALU,It stores the next instruction address,It holds only addresses,It is main memory,Medium,1.1,"The Accumulator holds operands/results. The PC stores next address. It holds data, not only addresses, and it is not RAM."
A smart fridge that monitors temperature and controls a compressor is an example of…,An embedded system,A supercomputer,A general-purpose desktop,A mainframe,Medium,1.1,It’s a dedicated controller inside an appliance.
Which pairing is most accurate for roles in FDE?,PC points to next instruction; MAR holds target address; MDR holds data,PC stores data; MAR stores results; MDR stores control signals,PC holds graphics; MAR holds sound; MDR holds video,PC always stores user input,Medium,1.1,"PC gives the next instruction address, MAR holds memory address for access, MDR holds the data transferred. Other pairings are incorrect."
Increasing clock speed without improving cooling may cause…,Thermal throttling that reduces performance,Permanent loss of RAM capacity,Fewer cores become available,The CU to stop decoding instructions forever,Medium,1.1,Higher clocks can increase heat; modern CPUs may throttle to protect themselves. RAM capacity and core count do not vanish; CU still decodes.
Why can embedded systems often use less power?,They perform a narrow set of tasks with simple hardware,They use multiple high‑power GPUs,They run at extremely high clock speeds by default,They require large cooling systems,Medium,1.1,"Specialised, efficient hardware for fixed tasks reduces power needs. High‑power GPUs, very high clocks, and big coolers are not typical."
What distinguishes Von Neumann architecture from Harvard?,Single memory for instructions and data,Separate instruction and data memories,No registers are used,It lacks an ALU,Medium,1.1,Von Neumann uses one memory; Harvard uses separate memories. Both use registers and an ALU.
"If a CPU often waits for RAM, which upgrade is most likely to help?","A larger, faster cache",A brighter display,More case fans with lights,A different keyboard,Medium,1.1,"Cache reduces average memory access time. Display, fans’ lights, and keyboards don’t affect the memory bottleneck directly."
An example of a control signal from the CU is to…,Enable a read from memory,Increase monitor brightness,Download an update from the internet,Change wallpaper,Medium,1.1,CU signals coordinate hardware actions like memory read/write or ALU operations. UI/network tasks are unrelated at this level.
"Which combination most likely speeds up a single-threaded, memory‑bound program?",Higher clock and larger cache,More cores only,A bigger SSD only,An external GPU,Medium,1.1,A single thread can benefit from higher clocks and fewer cache misses. Extra cores help less; storage/GPU are unrelated to CPU-memory delay.
Where are frequently needed instructions likely to be found for fastest access?,In the CPU cache,On secondary storage,Across the network,Only in the Accumulator,Medium,1.1,Cache stores frequently used data/instructions close to the CPU. Disk and network are much slower; the Accumulator is not for general storage.
Which is a realistic example of multiple cores helping performance?,Rendering frames where each core processes different parts,Loading a single small web page,Typing in a text editor,Moving the mouse pointer,Medium,1.1,"Computationally heavy, parallelisable tasks like rendering or video encoding benefit from multiple cores. Light tasks don’t scale much."
Which accurately describes data vs address?,Data is the value being processed; an address locates where it is stored,Both are the same thing,Address is the result of ALU operations,Data always equals the memory location number,Medium,1.1,Data is content; an address identifies a location. They are distinct concepts.
Which statement about embedded systems’ I/O is most accurate?,They use sensors/actuators relevant to their specific task,They always require a mouse and keyboard,They only use HDMI,They never use any inputs,Medium,1.1,"Embedded devices connect to task-specific inputs/outputs (e.g., sensors, motors). They rarely use typical desktop peripherals."
Which factor best explains why some CPUs add more cache levels (L1/L2/L3)?,"To provide a hierarchy balancing speed, size, and cost",To replace the CU entirely,To eliminate need for RAM,To reduce program size automatically,Medium,1.1,Cache levels create a balance: small/fast (L1) to larger/slower (L3). They don’t remove CU/RAM or shrink programs.
"If two CPUs have the same clock and cores but one has more cache, which workload benefits most?",One with frequent reuse of a working set that fits in cache,A workload that is entirely disk‑bound,One that depends on monitor brightness,One that relies on the number of USB ports,Medium,1.1,Cache helps when the working set fits and is reused. Disk‑bound or I/O/visual settings are irrelevant to CPU cache.
"Which best explains why the PC changes during program flow control (e.g., a jump)?",The next instruction address is set to the jump target,The Accumulator stores the next instruction,Cache erases the instruction,The CU stops issuing signals,Medium,1.1,Branch/jump control sets PC to a new address so the next fetch retrieves from that location. Accumulator/cache/CU statements are wrong.
Why is the Accumulator useful even when other general registers exist?,It simplifies ALU design by providing a default operand/result location,It stores the entire program,It replaces cache completely,It is used only for graphics,Medium,1.1,"An Accumulator-centric design makes arithmetic/logic simpler. It doesn’t store whole programs, replace cache, or do graphics‑only tasks."
Which example is clearly NOT an embedded system?,A tower desktop running many different applications,A car’s anti‑lock braking controller,A smart speaker’s microcontroller,A digital camera firmware,Medium,1.1,The desktop is general‑purpose. The others are dedicated controllers.
"When the CPU decodes an instruction that needs two operands from memory, what must happen first for each operand?",Its address must be placed in MAR to fetch it,Its value is guessed by the CU,It is loaded directly into the PC,It is stored permanently in cache,Medium,1.1,"Memory access uses MAR to specify addresses. Values aren’t guessed, don’t go to the PC, and cache is not permanent storage."
Which change most helps a parallelisable workload? (Medium #39),More CPU cores (with adequate cache),A shinier case,Lower RAM speed,Removing the CU,Medium,1.1,Parallel workloads benefit from more cores (and sufficient cache). Cosmetic changes or reducing RAM speed won’t help; CU is essential.
Which change most helps a parallelisable workload? (Medium #40),More CPU cores (with adequate cache),A shinier case,Lower RAM speed,Removing the CU,Medium,1.1,Parallel workloads benefit from more cores (and sufficient cache). Cosmetic changes or reducing RAM speed won’t help; CU is essential.
"CPU A: 3.0 GHz, 2 cores, 8 MB cache. CPU B: 2.4 GHz, 6 cores, 8 MB cache. For highly parallel rendering, which is likely faster and why?","CPU B, because more cores can process tasks in parallel despite a lower clock","CPU A, because higher clock always wins","CPU A, because fewer cores reduce overhead",They are identical in performance,Hard,1.1,Parallel rendering scales with core count; B’s 6 cores can outpace A’s 2 even at lower clock. Clock isn’t the only factor.
A program repeatedly accesses a small array of values. Which CPU feature most reduces average access time?,"Large, fast cache with high hit rate",Larger hard drive,Higher monitor refresh rate,More USB ports,Hard,1.1,"Cache keeps hot data close, cutting RAM latency. Storage, display, and USB don’t affect CPU memory latency."
Which sequence best summarises a simple fetch of the next instruction in Von Neumann architecture?,"PC → MAR, memory read to MDR, instruction decoded, PC updated","Accumulator → PC, cache write, CU erased","ALU → MAR, disk read to Accumulator, PC unchanged","PC → MDR, memory read to MAR, PC cleared",Hard,1.1,"Conceptually: PC provides address to MAR, memory read brings instruction to MDR, CU decodes, and PC updates. Other sequences are incorrect."
A workload spends most time waiting on RAM. Which combined change is most effective?,"Increase cache size and speed, and raise memory bandwidth/latency performance",Add RGB fans and lower clock,Use fewer cores only,Replace CU with another ALU,Hard,1.1,Memory‑bound tasks benefit from better cache and faster RAM. Cosmetic changes or reducing cores won’t help; CU is essential.
Why might a CPU with smaller cache and higher clock lose to one with larger cache and lower clock?,Frequent cache misses cause stalls that a higher clock cannot hide,Lower clock always wins,Cache doesn’t affect stalls,PC speed determines everything,Hard,1.1,Cache misses force slow RAM access; avoiding misses via larger cache can outweigh raw clock speed.
"In a branch instruction, what must happen to continue correct program flow?",PC is set to the branch target address,Accumulator is copied to MAR automatically,ALU disables the CU until next cycle,MDR is written to disk first,Hard,1.1,Control flow updates the PC to the target so the next fetch is correct. Other actions are irrelevant.
Which statement best distinguishes data and address in register usage?,MAR carries an address; MDR carries the data,PC carries data; Accumulator carries addresses,ALU carries addresses; CU carries data,Cache carries only addresses,Hard,1.1,MAR/MDR roles: address vs data. PC stores next instruction address; Accumulator stores results; cache stores both data and instructions.
An IoT sensor node runs from a small battery and sends periodic readings. Which design fits best?,"Embedded system with low‑power CPU, small memory, and task‑specific firmware",General‑purpose desktop board with dGPU,High‑clock multi‑core server CPU,Workstation with large upgradable RAM,Hard,1.1,"Constraints (power, cost, size) point to a minimal embedded design for a single task."
"CPU X: 3.2 GHz, 4 cores, 4 MB cache. CPU Y: 3.0 GHz, 4 cores, 16 MB cache. For a workload with frequent data reuse, which likely wins and why?","CPU Y, because larger cache improves hit rate and reduces stalls","CPU X, because 0.2 GHz is decisive","Both the same, cache size never matters","CPU X, because fewer cache levels are implied",Hard,1.1,"With the same cores/near clock, Y’s bigger cache can cut RAM trips, boosting performance on reuse-heavy workloads."
Which outcome is most consistent with Von Neumann bottleneck effects?,CPU waits due to shared pathway for instructions and data,CPU never waits because buses are separate,ALU must decode instructions,Accumulator stores both address and data simultaneously,Hard,1.1,Shared buses can cause contention. Harvard separates instruction/data paths; ALU doesn’t decode; Accumulator doesn’t store both forms at once.
A developer optimises code to improve spatial/temporal locality. Which hardware benefits most?,CPU cache hierarchy,CPU fan speed controller,Monitor scaler,Disk defragmenter,Hard,1.1,"Better locality increases cache hit rate. Fans, monitors, and disk tools don’t directly exploit this locality in CPU execution."
Which component directly determines the next instruction fetched after a conditional jump is taken?,Program Counter,Accumulator,MDR,MAR,Hard,1.1,The PC is set to the jump target; that address drives the next fetch. Accumulator/MDR/MAR have different roles.
Why might a quad‑core at 4 GHz perform worse than an octa‑core at 3 GHz on video encoding?,Encoding is highly parallel; more cores at slightly lower clock can finish sooner,Encoding can’t use multiple cores,Clock speed is irrelevant,Cache prevents parallelism,Hard,1.1,"Parallel tasks scale with cores. Clock still matters, but core count can dominate."
Which is the best justification for using embedded systems in appliances?,"They provide reliable, cost‑effective control tailored to specific tasks",They allow users to install any software,They guarantee maximum graphics performance,They require frequent manual upgrades,Hard,1.1,"Embedded controllers are specialised, low‑cost, and reliable for fixed functions, not general computing or graphics."
"During execute, the ALU needs an operand from memory. Which steps occur first?",CU sets MAR with the operand address; memory read brings it to MDR,PC writes result into Accumulator,MDR generates the address,Cache writes directly to disk,Hard,1.1,"Address goes to MAR; data is read into MDR, then ALU can use it. PC/Accumulator/disk roles are misstated in the distractors."
"Two CPUs: A has 2 cores at 4.0 GHz, B has 8 cores at 2.5 GHz. For single‑threaded code, which likely wins and why?","CPU A, because higher per‑core clock benefits single‑threaded execution","CPU B, because more cores always win",They are identical,"CPU B, because cache replaces clock speed",Hard,1.1,Single‑threaded tasks rely on one core’s speed; A’s higher clock helps more than extra cores that sit idle.
Which change least helps a memory‑bound single‑threaded workload?,Adding more cores without changing cache or memory,Larger cache,Lower memory latency,Slightly higher clock,Hard,1.1,"Extra cores don’t help a single thread waiting on memory. Cache, latency, and clock may reduce stalls."
Which is the best description of the Accumulator’s role relative to the ALU?,Default source/destination for many ALU operations,Permanent store for programs,Holds only addresses,Controls the clock signal,Hard,1.1,"Accumulator commonly supplies/receives ALU operands/results. It is not program storage, address‑only, or clock control."
Why does a larger L1 cache usually have a bigger performance impact than the same increase in L3 for tight loops?,"L1 is the closest and fastest cache, serving tight loops with minimal latency",L3 is faster than L1,Caches don’t help loops,L1 only stores graphics data,Hard,1.1,L1 has the lowest latency. Tight loops benefit most from the fastest cache. L3 is larger but slower; caches help instructions/data.
Embedded traffic‑light controllers often have which property?,"Real‑time responses with simple, deterministic control",High‑end GPUs rendering 3D scenes,Multi‑user virtualisation by default,Terabytes of upgradeable RAM,Hard,1.1,"They run simple control logic with timing constraints, not GPU/virtualisation/huge RAM features."
Which best explains why addresses and data are distinct in registers?,Addresses identify locations; data are the values stored there,Addresses are results of ALU addition only,Data cannot be stored in registers,Addresses are always smaller than data,Hard,1.1,Functionally distinct roles: location vs content. Addresses aren’t only ALU results; data can be in registers; sizes vary by design.
"For a program with many conditional branches, which hardware feature besides clock may strongly affect speed?",Cache effectiveness and how often required instructions/data are already available,Monitor refresh rate,Keyboard polling rate,Number of USB ports,Hard,1.1,Cache hits reduce stalls after branches. Peripherals don’t affect CPU instruction delivery.
Which register is most critical for determining control flow at runtime?,Program Counter,Accumulator,MDR,Cache tag,Hard,1.1,"The PC points to the next instruction, so changing it alters control flow. Other components don’t directly pick the next instruction address."
Why are embedded systems commonly cheaper than general‑purpose PCs for the same task?,"They include only the hardware needed for a specific, narrow function",They include extra unused components,They must support all possible applications,They require expensive discrete GPUs,Hard,1.1,"Specialisation removes unnecessary components, reducing cost."
"A CPU frequently executes a tight loop that fits in L1, but the data do not. What’s the likely performance issue?",Frequent data cache misses causing stalls despite instruction cache hits,No FDE cycle occurs,PC cannot update,ALU is disabled in loops,Hard,1.1,"Instruction hits help, but data misses still stall execution while waiting on RAM."
Which pair correctly matches register with typical contents during FDE?,PC: next instruction address; Accumulator: intermediate results,MAR: next instruction address; MDR: controls clock,Accumulator: next instruction address; PC: results,MDR: only addresses,Hard,1.1,"PC tracks the next instruction address; Accumulator holds results. MAR/MDR roles are address/data, not clock; MDR doesn’t hold addresses only."
A robotics controller must respond predictably to sensor inputs. Which design aspect is most critical?,"Deterministic, real‑time embedded firmware and I/O",A fancy GUI theme,High‑end discrete graphics,Dozens of general‑purpose background apps,Hard,1.1,Real‑time determinism is key for control. GUI/GPUs/background apps are irrelevant.
"CPU A: 3.5 GHz, 4 cores, 6 MB cache. CPU B: 3.2 GHz, 4 cores, 12 MB cache. Data working set ≈10 MB. Which and why?","CPU B, because its cache can hold more of the working set, reducing RAM stalls","CPU A, because small cache is always faster","Either, because cache size never matters","CPU A, because cores are higher",Hard,1.1,"With same cores/near clocks, B’s bigger cache fits more data, reducing misses."
Which situation most demonstrates the von Neumann bottleneck?,Instruction fetches and data reads contend for the same memory bus,ALU replaces the CU,Cache is slower than RAM,Programs can’t be stored in memory,Hard,1.1,Shared buses cause contention for instruction and data transfers.
"In the execute stage, the CU signals the ALU to perform addition. Where is the result commonly placed?",In the Accumulator,In the MAR,In the PC,In the MDR as an address,Hard,1.1,"ALU results typically go to the Accumulator. MAR holds addresses; PC holds next address; MDR carries data, not addresses as results."
A wearable fitness tracker should prioritise which CPU characteristics?,Low power consumption and sufficient performance for its specific tasks,Maximum core count regardless of power,Discrete GPU support,User‑replaceable desktop CPU socket,Hard,1.1,Battery‑powered embedded devices need efficiency over raw core count or desktop‑class features.
Which change could paradoxically reduce performance for some memory‑bound codes?,"Raising clock speed without improving memory/cache, increasing time stalled per useful work",Adding relevant cache,Reducing memory latency,Improving cache hit rate,Hard,1.1,"If stalls dominate, higher clock can spend more cycles waiting, raising power/heat without equivalent speedup."
Why is separating ‘data’ and ‘address’ conceptually important for registers and buses?,It lets the CPU specify where to access and what value to move/compute distinctly,Because addresses are computed only once at boot,Because data can only exist in RAM,Because addresses are always 8 bits,Hard,1.1,Distinct roles avoid confusion: location vs value. Addresses aren’t only computed at boot; data can be in registers; sizes vary.
A car’s airbag controller must react within milliseconds on sensor triggers. What kind of system is appropriate?,A real‑time embedded system with deterministic response,A general workstation with many background services,A gaming console,A file server,Hard,1.1,Safety‑critical control needs deterministic real‑time embedded design.
Which upgrade path best improves both CPU and memory performance for single‑threaded scientific code with locality?,Slightly higher clock and significantly larger/faster cache,Only adding more cores,Only a brighter screen,Only a larger SSD,Hard,1.1,"Single‑threaded, locality‑friendly code benefits from faster per‑core speed and cache hit rate."
Which description of the CU’s role during FDE is most precise?,It orchestrates control signals to move addresses/data between registers and trigger ALU/memory operations,It stores long‑term user files,It renders graphics,It acts as main memory,Hard,1.1,"The CU coordinates operations; it is not storage, graphics, or RAM."
Why do many embedded systems use ROM/flash for their software?,It’s non‑volatile and can store dedicated firmware that rarely changes,It is faster than all caches,It requires a keyboard to boot,It is only available in desktop PCs,Hard,1.1,Firmware in non‑volatile memory suits dedicated devices; it isn’t faster than cache and doesn’t require desktop peripherals.
"In a memory‑bound loop, which combo most reduces stall time?",Higher cache hit rate and lower RAM latency,More RGB lighting,Removing cores entirely,A larger monitor,Hard,1.1,Stalls fall when the CPU waits less on RAM—achieved via better cache and faster memory. Cosmetics don’t help.